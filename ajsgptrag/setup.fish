#!/usr/bin/env fish

# Wikipedia RAG System Setup Script for Fish Shell
# This script helps set up the Wikipedia RAG system

echo "ğŸš€ Setting up Wikipedia RAG System..."
echo "======================================"

# Check Python version
echo "ğŸ“‹ Checking Python version..."
set python_version (python3 --version 2>&1 | awk '{print $2}' | cut -d. -f1,2)
set required_version "3.8"

if test (printf '%s\n' $required_version $python_version | sort -V | head -n1) = $required_version
    echo "âœ… Python $python_version is compatible (>= $required_version)"
else
    echo "âŒ Python $python_version is not compatible. Please install Python >= $required_version"
    exit 1
end

# Create virtual environment
echo "ğŸ Creating virtual environment..."
if not test -d "venv"
    python3 -m venv venv
    echo "âœ… Virtual environment created"
else
    echo "âœ… Virtual environment already exists"
end

# Activate virtual environment
echo "ğŸ”§ Activating virtual environment..."
source venv/bin/activate.fish

# Upgrade pip
echo "ğŸ“¦ Upgrading pip..."
pip install --upgrade pip

# Install dependencies
echo "ğŸ“š Installing dependencies..."
pip install -r requirements.txt

echo "âœ… Dependencies installed successfully!"

# Create data directories
echo "ğŸ“ Creating data directories..."
mkdir -p data models .cache
echo "âœ… Directories created"

# Download embedding model (optional)
echo "ğŸ¤– Pre-downloading embedding model (optional)..."
python3 -c "
try:
    from sentence_transformers import SentenceTransformer
    print('Downloading intfloat/e5-base-v2...')
    model = SentenceTransformer('intfloat/e5-base-v2')
    print('âœ… Embedding model downloaded successfully!')
except Exception as e:
    print(f'âš ï¸  Could not download embedding model: {e}')
    print('   Model will be downloaded automatically on first use.')
"

# Check if tests pass
echo "ğŸ§ª Running tests..."
python3 -m pytest tests/ -v --tb=short; or echo "âš ï¸  Some tests failed, but installation continues..."

echo ""
echo "ğŸ‰ Setup completed!"
echo "==================="
echo ""
echo "Next steps:"
echo "1. Configure your LLM in src/llm_interface.py (see llm_config_examples.py)"
echo "2. Set LLM_MODEL_PATH environment variable:"
echo "   set -x LLM_MODEL_PATH '/path/to/your/Mistral-7B-Instral-v0.3-Q6_K.gguf'"
echo ""
echo "Quick start:"
echo "  python3 cli.py                    # Interactive mode"
echo "  python3 cli.py -q 'What is AI?'   # Single query"
echo "  python3 examples/demo.py          # Run demo"
echo ""
echo "Documentation:"
echo "  README.md                         # Full documentation"
echo "  llm_config_examples.py           # LLM configuration examples"
echo ""
echo "Happy querying! ğŸš€"
